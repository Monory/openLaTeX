\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtext}
\usepackage{mathtools}
\usepackage{microtype}
\usepackage{cleveref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\crefformat{footnote}{#2\footnotemark[#1]#3}

\newtheorem*{lemma}{Лемма}
\theoremstyle{remark}
\newtheorem*{note}{Заметка}
\theoremstyle{definition}
\newtheorem{question}{Вопрос}
\numberwithin{question}{subsection}

\everymath{\displaystyle}
\begin{document}
\sloppy
\author{Чудинов Никита (группа 104)\thanks{Отдельное спасибо 104 группе за помощь в исправлении ошибок и предоставлении материала.}}
\date{}
\title{\vspace{-2.0cm}Ответы на вопросы к коллоквиуму по линейной алгебре и геометрии 15-16~мая}
\frenchspacing

\maketitle

\section{Комплексные числа}
\subsection{Билет 1}
\begin{question}[Что такое поле?]
Поле --- алгебраическая структура, для элементов которой определены операции сложения и умножения с определёнными свойствами:
\begin{enumerate}
	\item Коммутативность сложения
	\item Ассоциативность сложения
	\item Существование нулевого элемента
	\item Существование противоположного элемента
	\item Коммутативность умножения
	\item Ассоциативность умножения
	\item Существование единичного элемента
	\item Существование обратного элемента для ненулевых элементов
	\item Дистрибутивность умножения относительно сложения
\end{enumerate}
Аксиомы 1--4 соответствуют определению коммутативной группы по сложению, 5--8 коммутативной группы по умножению, а аксиома 9 связывает сложение и умножение. 
\end{question}

\begin{question}[Докажите, что в поле обратный элемент к любому ненулевому элементу определяется единственным образом]
\(\) % хак для того, чтобы строка не убегала
\begin{proof}
Пусть \(b', b''\) --- обратные элементу \(a\). Тогда:
\begin{equation*}
	b' = b'1 = b'(ab'') = (b'a)b'' = 1b'' = b'' \qedhere
\end{equation*}
\end{proof}
\end{question}

\begin{question}[Приведите примеры бесконечных полей и докажите, что они удовлетворяют требуемым свойствам]
\(\mathbb{Q, R, C}\) --- доказательство остаётся читателю как упражнение.
\end{question}

\begin{question}[Докажите, что существует поле из двух элементов]
Пример такого поля --- поле вычетов по модулю 2. Доказательство тривиально и состоит из проверки всех теорем. 
\end{question}


\subsection{Билет 2} 
\begin{question}[Что такое комплексные числа?]
Комплексные числа (\(\mathbb{C}\)) --- числа вида \(x + iy\), где \(x\) и \(y\) --- вещественные числа, а \(i\) --- мнимая единица (величина, для которой выполняется равенство \(i^2 = -1\)).
\end{question}
	
\begin{question}[Дайте определение арифметических операций над комплексными числами]\(\)
\begin{enumerate}
	\item Сложение: \((a + bi) + (x + yi) = (a+b) + (x+y)i\)
	\item Взятие противоположного: \(-(a + bi) = (-a + (-b)i)\)
	\item Умножение: \((a + bi) \times (x + yi) = ((ax - by) + (ay + bx)i)\)
	\item Взятие обратного: \((a + bi)^{-1} = \dfrac{a}{a^2 + b^2} - \left(\dfrac{b}{a^2 + b^2}\right)i\)
\end{enumerate}
\end{question}

\begin{question}[Докажите, что множество комплексных чисел образует поле]
Доказательство остаётся читателю как упражнение.
\end{question}

\begin{question}[Сформулируйте основную теорему алгебры и докажите её для многочленов второй степени]
Всякий отличный от константы многочлен с комплексными коэффициентами имеет, по крайней мере, один корень на поле комплексных чисел.
\begin{proof}[Доказательство основной теоремы алгебры для многочленов степени 2]
Рассмотрим обычное решение квадратных уравнений:
\begin{align*}
	ax^2 + bx + c &= 0 \\
	D &= b^2 - 4ac \\
	x &= \frac{-b \pm \sqrt{D}}{2a}
\end{align*}
Так как \(D\) --- комплексное и \(a \neq 0\), то решение последнего уравнения существует. Таким образом мы нашли корень произвольного многочлена второй степени в \(\mathbb{C}\).
\end{proof}
\end{question}


\subsection{Билет 3}

\begin{question}[Что такое модуль и аргумент комплексного числа?]
Рассматривая комплексные числа вида \((a + bi)\), мы можем поместить их на плоскость, с осью абсцисс обозначающей значение \(a\), и осью ординат, обозначающей значение \(b\). Такое изображение называется комплексной плоскостью.

Тогда модулем комплексного числа будет называться длина радиус вектора соответствующей точки комплексной плоскости.

Аргументом комплексного числа называется угол между вектором и положительным направлением оси абсцисс. 
\end{question}


\begin{question}[Как модуль и аргумент ведут себя при перемножении комплексных чисел?]
Модули комплексных чисел при умножении перемножаются, а аргументы складываются.
\begin{proof}
Из школьного курса геометрии мы знаем, как получить координаты вектора, зная его длину и угол поворота. Допустим, мы имеем комплексное число \(a\) с модулем \(|a| = z\) и аргументом \(\arg(a) = \varphi\). Тогда
\begin{align*}
	x_a &= z\cos(\varphi); \\
	y_a &= z\sin(\varphi).
\end{align*}
Записав это в обычной форме мы получим \(a = z(\cos(\varphi) + i\sin(\varphi))\) --- это называется тригонометрической формой комплексного числа.

Рассмотрим теперь умножение двух комплексных чисел в тригонометрической форме:
\begin{align*}
	a &= y(\cos\varphi + i\sin\varphi) \\
	b &= z(\cos\psi + i\sin\psi) \\
	ab &= yz(\cos\varphi + i\sin\varphi)(\cos\psi + i\sin\psi) \\
	ab &= yz(\cos\varphi\cos\psi + i\cos\varphi\sin\psi + i\sin\varphi\cos\psi - \sin\varphi\sin\psi) \\
	ab &= yz((\cos\varphi\cos\psi - \sin\varphi\sin\psi) + i(\cos\varphi\sin\psi + \sin\varphi\cos\psi)) \\
	ab &= yz(\cos(\varphi + \psi) + i\sin(\varphi + \psi)) \\
	|ab| &= yz \\
	\arg(ab) &= \varphi + \psi
\end{align*}
\end{proof}
\end{question}


\begin{question}[Докажите, что каждое ненулевое комплексное число имеет ровно \(n\) корней \(n\)-й степени и опишите способ их нахождения]
Сначала докажем количество корней.
\begin{lemma}[Теорема Безу]
Если \(x_1\) --- корень многочлена \(f(x)\), степень которого равна \(n\), то мы можем разложить этот многочлен как
\begin{equation*}
	f(x) = (x - x_1) \cdot g(x),
\end{equation*}
где \(g(x)\) --- многочлен степени \(n - 1\).

\begin{proof}[Доказательство теоремы Безу]
Поделим \(f(x)\) на \(x - x_1\) с остатком, получим
\begin{align*}
	f(x) &= (x - x_1) \cdot g(x) + r \\
	x &= x_1 \\
	f(x_1) &= 0 \cdot g(x) + r \\
	f(x_1) &= r \\
	\text{Так как \(x_1\) --- корень, то }f(x_1) &= 0 \\
	r &= 0 \qedhere
\end{align*}
\end{proof}
\end{lemma}

Опираясь на основную теорему и теорему Безу, узнаём, что у уравнения степени \(n\) ровно \(n\) различных корней.  


Для поиска корней проще всего использовать формулу Эйлера.
\begin{lemma}[Формула Эйлера]
\(e^{ix} = \cos(x) + i\sin(x)\).
\begin{proof}[Доказательство леммы]
Используем ряды Тейлора. Разложим функцию \(e^{ix}\) в ряд Тейлора в окрестности точки \(a = 0\) по степеням \(x\). Получим
\begin{align*}
	e^{ix} &= 1 + \dfrac{ix}{1!} + \dfrac{(ix)^2}{2!} + \dfrac{(ix)^3}{3!} + \dfrac{(ix)^4}{4!} + \dfrac{(ix)^5}{5!} + \dfrac{(ix)^6}{6!} + \dots \\
	&= 1 + ix - \dfrac{x^2}{2!} - \dfrac{ix^3}{3!} + \dfrac{x^4}{4!} + \dfrac{ix^5}{5!} - \dfrac{x^6}{6!} + \dots \\	
	&= (1 - \dfrac{x^2}{2!} + \dfrac{x^4}{4!} - \dfrac{x^6}{6!} + \dots) + i(\dfrac{x}{1!} - \dfrac{x^3}{3!} + \dfrac{x^5}{5!} - \dots) \\
	&= \cos{}x + i\sin{}x \qedhere
\end{align*}
\end{proof}
\end{lemma}

\begin{lemma}[Формула Муавра]\(\)
\begin{align*}
	a &= z(\cos(\varphi + 2\pi{}k) + i\sin(\varphi + 2\pi{}k); \\
	a &= ze^{i(\varphi + 2\pi{}k)} \\
	a^n &= z^ne^{i(\varphi + 2\pi{}k)n} \\
	a^n &= z^n(\cos(n\varphi + 2\pi{}nk) + i\sin(n\varphi + 2\pi{}nk))
\end{align*}
\end{lemma}
Отсюда,
\begin{equation*}
	\sqrt[n]{a} = \left\{\sqrt[n]{z}\left(\dfrac{\cos(n\varphi)}{2\pi{}nk} + i\dfrac{\sin(n\varphi)}{2\pi{}nk}\right)\right\}; k \in \{0, 1, \dots, n-1\}
\end{equation*}
\end{question}


\subsection{Билет 4}
\begin{question}[Что такое кратность корня многочлена?]
Говорят, что корень \(c\) имеет кратность \(m\), если рассматриваемый многочлен делится на \((x-c)^m\) и не делится на \((x-c)^{m+1}\).
\end{question}


\begin{question}[Докажите, что сумма кратностей корней многочлена с комплексными коэффициентами равна его степени]\(\)
\begin{proof}
Представим корень \(x_i\) кратности \(k_i\) как \(k_i\) равных между собой корней кратности 1. Сумма кратностей при этом не меняется. Но количество таких корней равно степени многочлена по основной теореме алгебры.
\end{proof}
\end{question}


\begin{question}[Докажите, что каждый многочлен положительной степени с действительными коэффициентами разложим на линейные и квадратичные множители, также с действительными коэффициентами]
Для начала докажем вспомогательное утверждение
\begin{lemma}
Если \(x = (a + bi)\) --- корень многочлена и коэффициенты многочлена вещественны, то cопряжённый к нему \(\overline{x} = (a - bi)\) --- тоже корень.
\begin{proof}
Для начала докажем вспомогательное утверждение
\begin{lemma}[О возведении сопряжённых чисел в степень]
\(\overline{x}^k = \overline{x^k}\)
\begin{proof}
При \(k = 1\) истинность очевидна. Предположим, что для некоторого k утверждение истинно, тогда \(\overline{x}^{k+1}  = \overline{x}^k \cdot \overline{x} = \overline{x^k} \cdot \overline{x}\). Свели задачу к более простой, теперь надо доказать, что для произвольных \(x, y: \overline{x} \cdot \overline{y} = \overline{x \cdot y}\).
\begin{align*}
	x &= a + bi \\
	\overline{x} &= a - bi \\
	y &= c + di \\
	\overline{y} &= c - di\\
	x \cdot y &= (ac - bd) + (bc + ad)i \\
	\overline{x} \cdot \overline{y} &= (ac - bd) - (bc + ad)i \\
	\overline{x \cdot y} &= (ac - bd) - (bc + ad)i \\
	\overline{x} \cdot \overline{y} &= \overline{x \cdot y} \qedhere
\end{align*}
\end{proof}
\end{lemma}

\begin{align*}
	f(\overline{x_i}) &= f_n\overline{x_i^n} + f_{n-1}\overline{x_i^{n-1}} + \dots + f_1\overline{x_i} + f_0 \\
	f(\overline{x_i}) &= \overline{f_nx_i^n} + \overline{f_{n-1}x_i^{n-1}} + \dots + \overline{f_1x_i} + \overline{f_0} \\
	\overline{f(x_i)} &= f(\overline{x_i}) \\
	\overline{0} &= 0 \qedhere
\end{align*}
\end{proof}
\end{lemma}

\begin{proof}
Каждому вещественному корню соответствует одночлен вида \((x - x_i)\), согласно теореме Безу. Рассмотрим комплексные корни. Каждому корню \(l + mi\) соответствует (по лемме) сопряжённый корень \(l - mi\), но \((x - l - mi)(x - l + mi) = (x - l)^2 - (mi)^2 = x^2 - 2lx + l^2 + m^2\). Тогда если \(a = -2l, b = l^2 + m^2\), то многочлен раскладывается в произведение 
\begin{equation*}
	(x - x_1)^{k_1}(x - x_2)^{k_2}\dots(x - x_s)^{k_s}(x^2 + a_{s+1}x + b_{s+1})^{k_{s+1}}\dots(x^2 + a_nx + b_n)^{k_n} \qedhere
\end{equation*}
\end{proof}
\end{question}


\begin{question}[Сформулируйте и докажите теорему Виета для многочленов произвольной степени]
Если \(c_1,c_2,\dots,c_n\) --- корни многочлена \(x^n + a_{n-1}x^{n-1} + a_{n-2}x^{n-2} + \dots + a_0 = 0\) (каждый корень взят соответствующее его кратности число раз), то коэффициенты \(a_{n-1}, \dots, a_0\) выражаются в виде многочленов от корней, а именно:
\begin{align*}
    a_{n-1} &= -(c_1 + c_2 + \dots + c_n) \\
    a_{n-2} &= c_1c_2 + c_1c_3 + \dots + c_1c_n + c_2c_3 + \dots + c_{n-1}c_n \\
    \dots &= \dots \\
    a_{k} &= \sum_{1 \leqslant j_1 < \dots < j_{n-k} \leqslant n}(-1)^{n-k} x_{j_1} \dots x_{j_{n-k}} \\
    \dots &= \dots \\
    a_1 &= (-1)^{n-1}(c_1c_2\dots{}c_{n-1} + c_1c_2\dots{}c_{n-2}c_n + \dots + c_2c_3\dots{}c_n) \\
    a_0 &= (-1)^nc_1c_2\dots{}c_n
\end{align*}

\begin{proof}
Раскроем \(f(x) = (x-x_1)(x-x_2)\dots(x-x_n)\). Получим \(2^n\) слагаемых, каждое из которых равно \((-1)^{n-k}x_1b_1\dots{}x_nb_nx^k\), где \(b_i\) равняется нулю или единице, соответствуя тому, включили ли мы этот корень в слагаемое или нет, а \(k\) --- количество исключённых корней.
\end{proof}
\end{question}


\subsection{Билет 5}

\begin{question}[Что такое линейное пространство над произвольным полем?]
Линейное пространство \(V\) над полем \(F\) --- это четвёрка \((V, F, +, \cdot)\), где
\begin{enumerate}
	\item \(V\) --- непустое множество элементов произвольной природы, которые называются векторами
	\item \(F\) --- поле, элементы которого называются скалярами
	\item \(+: V \times V \rightarrow V\) --- операция сложения векторов
	\item \(\cdot: F \times V \rightarrow V\) --- операция умножения скаляра на вектор
\end{enumerate}
При этом выполняются следующие аксиомы:
\begin{enumerate}
	\item Коммутативность сложения
	\item Ассоциативность сложения
	\item Существование нейтрального элемента относительно сложения
	\item Существование противоположного элемента относительно сложения
	\item Ассоциативность умножения на скаляр
	\item Унитарность (умножение вектора на нейтральный элемент в поле сохраняет вектор)
	\item Дистрибутивность умножения на вектор относительно сложения скаляров
	\item Дистрибутивность умножения на скаляр относительно сложения векторов
\end{enumerate}
\end{question}


\begin{question}[Что такое комплексификация действительного пространства и что такое овеществление комплексного пространства?]
Пусть \(W_{\mathbb{R}}\) --- действительное пространство. Тогда \emph{комплексификация} пространства \(W = W_{\mathbb{R}}\) --- это множество
\begin{equation*}
	W_{\mathbb{C}} = W \times W = \{(u, v);\;u, v \in W\}
\end{equation*}
с операцией
\begin{equation*}
	(a + bi)(\vec{u}, \vec{v}) = (a\vec{u} - b\vec{v}, a\vec{v} + b\vec{u})
\end{equation*}
При этом мы отождествляем \(w \in W\) с \((w, 0)\). Тогда \(i \cdot w = (0, w)\).

Пример: \(\mathbb{R_C} = \mathbb{C}\)

Пусть \(V\) --- комплексное линейное пространство. Тогда \emph{овеществление} пространства \(V\) --- это то же множество \(V\), рассмотренное как пространство над \(\mathbb{R}\). Так как \(\mathbb{R} \subset \mathbb{C}\), то это возможно. Обозначается \(V_{\mathbb{R}}\).
Таким образом при овеществлении <<забывается>>, как умножать на мнимую единицу.
Пример: \(\mathbb{C}_{\mathbb{R}} = \mathbb{R}^2\)
\end{question}


\begin{question}[Докажите, что комплексификация, и, соответственно, овеществление, являются линейными пространствами над соответствующими полями и найдите их размерности]
Доказательство остаётся читателю как упражнение.

Размерность пространства после комплексификации увеличивается в два раза, размерность пространства после овеществления не меняется.
\end{question}


\begin{question}[Постройте комплексификацию пространства \(\mathbb{R}^n\) и овеществление пространства \(\mathbb{C}^n\)]
\(\mathbb{R}^n_{\mathbb{C}} = \mathbb{C}^n\)

\(\mathbb{C}^n_{\mathbb{R}} = \mathbb{R}^{2n}\)
\end{question}


\section{Линейные пространства}
\subsection{Билет 6}
\begin{question}[Что такое сумма подпространств в произвольном линейном пространстве \(V\) над произвольным полем \(F\)?]
Суммой подпространств \(U\) и \(W\) называется наименьшее подпространство в \(V\), содержащее \(U\) и \(W\), то есть 
\begin{equation*}
	U + W = \{u + w: u \in U, w \in W\}
\end{equation*}
\end{question}


\begin{question}[Докажите, что сумма и пересечение двух подпространств \(U\) и \(W\) --- снова подпространство]
Это доказательство очевидно и остаётся читателю как упражнение.
\end{question}


\begin{question}[Как размерности \(U + W\) и \(U \cap W\) связаны с размерностями пространств \(U\) и \(W\)?]\(\)
\begin{equation*}
	\dim U + \dim W = \dim (U + W) + \dim(U \cap W)
\end{equation*}
\begin{proof}
Пусть \(F = U + W\), \(G = U \cap W\), \(\dim G = g\). Выберем в \(G\) базис \((e_1, e_2, \dots, e_g)\). Так как \(G \subset U\) и \(G \subset W\), базис \(G\) можно дополнить до базиса \(U\) и базиса \(W\). Пусть \(E_U = (e_1, \dots, e_g, p_1, \dots, p_u)\) --- базис подпространства \(U\) и пусть \(E_W = (e_1, \dots, e_g, q_1, \dots, q_w)\) --- базис подпространства \(W\). Покажем, что \(E_F = (e_1, \dots, e_g, p_1, \dots, p_u, q_1, \dots, q_w)\) --- базис подпространства \(F = U + W\). Для этого необходимо, чтобы они были линейно независимы и любой вектор пространства \(F\) можно было бы представить их линейной комбинацией.

Докажем линейную независимость векторов \(E_F\). Пусть нулевой вектор пространства \(F\) представляется линейной комбинацией векторов \(E_F\) c некоторыми коэффициентами:
\begin{equation*}
	\alpha_1{}e_1 + \alpha_2{}e_2 + \dots + \alpha_g{}e_g + \beta_1{}p_1 + \dots + \beta_u{}p_u + \gamma_1{}q_1 + \dots + \gamma_w{}q_w = 0
\end{equation*}
\begin{equation*}
	\alpha_1{}e_1 + \alpha_2{}e_2 + \dots + \alpha_g{}e_g + \beta_1{}p_1 + \dots + \beta_u{}p_u = -\gamma_1{}q_1 - \dots - \gamma_w{}q_w
\end{equation*}
Левая часть является вектором подпространства \(U\), а правая --- вектором подпространства \(W\), следовательно, вектор \(\xi\)
\begin{equation*}
	\xi = \alpha_1{}e_1 + \alpha_2{}e_2 + \dots + \alpha_g{}e_g + \beta_1{}p_1 + \dots + \beta_u{}p_u = -\gamma_1{}q_1 - \dots - \gamma_w{}q_w	
\end{equation*}
принадлежит пространству \(G = U \cap W\). В таком случае вектор \(\xi\) можно представить линейной комбинацией векторов подпространства \(G\):
\begin{equation*}
	\xi = \delta_1{}e_1 + \dots + \delta_g{}e_g 	
\end{equation*}
Из предыдущих уравнений имеем
\begin{equation*}
	\delta_1{}e_1 + \dots + \delta_g{}e_g = -\gamma_1{}q_1 - \dots - \gamma_w{}q_w
\end{equation*}
\begin{equation*}
	\delta_1{}e_1 + \dots + \delta_g{}e_g + \gamma_1{}q_1 + \dots + \gamma_w{}q_w = 0
\end{equation*}
Но векторы \(e_1, \dots, e_g, q_1, \dots, q_w\) --- базис подпространства \(W\), следовательно, линейно независимы, следовательно, \(\delta_1 = \dots = \delta_g = q_1 = \dots = q_w = 0\), тогда \(0\) в \(E_F\) примет вид
\begin{equation*}
	\alpha_1{}e_1 + \alpha_2{}e_2 + \dots + \alpha_g{}e_g + \beta_1{}p_1 + \dots + \beta_u{}p_u = 0
\end{equation*}
Но это --- базис подпространства \(U\), а, значит, \(\alpha_1 = \dots = \alpha_g = \beta_1 = \dots = \beta_u = 0\). Подытоживая, получаем, что векторы \(E_F\) --- линейно независимые.

Любой вектор \(z\) из \(F\), по определению суммы подпространств, можно представить суммой \(x + y, x \in U, y \in W\). В свою очередь, \(x\) представляется линейной комбинацией векторов \(E_U\), а \(y\) --- линейной комбинацией \(E_W\). Следовательно, векторы \(E_F\) порождают пространство \(F\). Получили, что \(E_F\) --- базис \(F\).

Изучая базисы подпространств \(U\) и \(W\), имеем, что \(\dim U = g + u, \dim W = g + w, \dim (U + W) = g + u + w\), следовательно
\begin{equation*}
	\dim U + \dim W - \dim (U \cap W) = \dim (U + W) \qedhere
\end{equation*}
\end{proof}
\end{question}


\subsection{Билет 7}
\begin{question}[Что такое матрица перехода от одного базиса линейного пространства к другому (она же --- матрица замены координат)?]
Матрицей перехода от базиса \(a\) к базису \(b\) (или матрицей замены координат) называется такая матрица \(n \times n\)
\begin{equation*}
    T = T_{a \rightarrow b} = (t_{ij})_{n \times n}
\end{equation*}
у которой в \(j\)-том столбце стоит вектор-столбец \((b_j)_a\) --- координаты \(\vec{b_j}\) в базисе \(a\), то есть
\begin{equation*}
    (b_j)_a =
    \begin{pmatrix}
        t_{1j} \\
        \vdots \\
        t_{nj}
    \end{pmatrix} 
\end{equation*}
\end{question}


\begin{question}[Как с её помощью вычислять координаты вектора в различных базисах?]
\(\forall \vec{x} \in V\) связь координат вектора \(\vec{x}\) в базисах \(a\) и \(b\) определяется формулой
\begin{equation*}
     \vec{x_a} = T_{a \rightarrow b}\vec{x_b}
\end{equation*} 

Пусть \(x_1, \dots, x_n\) --- координаты вектора \(x\) в базисе \(a_1, \dots, a_n\), а \(x'_1, \dots, x'_n\) --- координаты в базисе \(b_1, \dots, b_n\). Тогда два набора координат связаны следующими формулами:
\begin{align*}
	x_1 &= t_{11}x'_1 + \dots + t_{1n}x'_n \\
	\dots &= \dots \\
	x_n &= t_{n1}x'_1 + \dots + t_{nn}x'_n
\end{align*}

\begin{proof}
\begin{align*}
	&x = x'_1b_1 + \dots + x'_nb_n = \\ 
	&x'_1(t_{11}a_1 + \dots + t_{n1}a_n) + \dots + x'_n(t_{1n}a_1 + \dots + t_{nn}a_n) = \\ 
	&(t_{11}x'_1 + \dots + t_{1n}x'_n)a_1 + \dots + (t_{n1}x'_1 + \dots + t_{nn}x'_n)a_n = \\
	&x_1a_1 + \dots + x_na_n
\end{align*}
Так как \(a_1, \dots, a_n\) --- базис, мы получаем, что \(x_i = t_{i1}x'_1 + \dots + t_{in}x'_n\) для \(i = 1, \dots, n\).
\end{proof}
\end{question}

\begin{question}[Как связаны матрицы перехода от одного базисак другому, от другого --- к третьему и от первого --- к третьему?]
Пусть имеются три базиса \(e, f, g\) пространства \(V\) и известны матрицы перехода \(T_{e \rightarrow f}, T_{f \rightarrow g}, T_{e \rightarrow g}\). Тогда
\begin{equation*}
	T_{e \rightarrow g} = T_{e \rightarrow f} \cdot T_{f \rightarrow g}
\end{equation*}

\begin{proof}
\begin{align*}
	f &= e \cdot T_{e \rightarrow f} \\
	g &= f \cdot T_{f \rightarrow g} \\
	g &= e \cdot T_{e \rightarrow g}
\end{align*}
Подставляя первое выражение во второе равенство, получаем \(g = e \cdot T_{e \rightarrow f} \cdot T_{f \rightarrow g}\). Сравнивая с третьим равенством, приходим к изначальному утверждению.
\end{proof}
\end{question}


\begin{question}[Докажите, что матрица замены координат в линейном пространстве всегда невырожденная]\(\)
\begin{proof}
Очевидно, что матрицей перехода из базиса \(e\) в базис \(e\) является единичная матрица \(E\). Используем предыдущее утверждение, при \(g = e\).
\begin{align*}
	g &= e \cdot T_{e \rightarrow f} \cdot T_{f \rightarrow g} \\
	e &= e \cdot T_{e \rightarrow f} \cdot T_{f \rightarrow g} \\
	E &= T_{e \rightarrow f} \cdot T_{f \rightarrow g}
\end{align*}
Следовательно, всегда существует матрица перехода в другую сторону, она равняется обратной матрице перехода и всегда невырождена.
\end{proof}
\end{question}



\section{Линейные отображения}
\subsection{Билет 8}
\begin{question}[Что такое линейное отображение (иногда оно называется ещё \emph{линейным преобразованием}) и линейный оператор?]
Отображение \(\varphi\) из линейного пространства \(V\) в линейное пространство \(W\) над одним и тем же полем \(F\) называется линейным, если для любых \(x, y \in V\) и \(\alpha \in F\) выполняется
\begin{align*}
    1)\quad&\varphi(x + y) = \varphi(x) + \varphi(y) \\
    2)\quad&\varphi(\alpha{}x) = \alpha\varphi{}(x)
\end{align*}

Линейное отображение пространства в само себя называется линейным оператором.
\end{question}


\begin{question}[Докажите, что поворот плоскости \(\mathbb{R}^2\) на угол \(\alpha\) является линейным преобразованием]\(\)
\begin{proof}
В двумерном пространстве поворот можно описать одним углом \(\alpha\) со следующей матрицей линейного преобразования:
\begin{equation*}
	M(\alpha) =
	\begin{pmatrix}
		\cos \alpha & -\sin \alpha \\
		\sin \alpha & \cos \alpha
	\end{pmatrix}
\end{equation*}

Тогда \(a' = M(\alpha)a, b' = M(\alpha)b, (a+b)' = M(\alpha)(a+b)\). Но
\begin{align*}
	a'_x &= a_x \cos\alpha - a_y \sin\alpha \\
	a'_y &= a_x \sin\alpha + a_y \cos\alpha \\
	b'_x &= b_x \cos\alpha - b_y \sin\alpha \\
	b'_y &= b_x \sin\alpha + b_y \cos\alpha \\
	(a' + b')_x &= (a_x + b_x)\cos\alpha - (a_y + b_y)\sin\alpha = (a + b)'_x \\
	(a' + b')_y &= (a_x + b_x)\sin\alpha + (a_y + b_y)\sin\alpha = (a + b)'_y 
\end{align*}
Также,
\begin{align*}
	(c \cdot a)'_x &= c \cdot a_x \cos\alpha - c \cdot a_y \sin\alpha = c \cdot a'_x  \\
	(c \cdot a)'_y &= c \cdot a_x \sin\alpha + c \cdot a_y \cos\alpha = c \cdot a'_y \qedhere
\end{align*}
\end{proof}
\end{question}


\begin{question}[Докажите, что дифференцирование является линейным преобразованием]\(\)
\begin{proof}
Пусть есть функции \(f = f(x), g = g(x)\) и константа \(\alpha\). Тогда
\begin{align*}
	(\alpha \cdot f)' &= \alpha \cdot f' \\
	(f + g)' &= f' + g' \qedhere
\end{align*}
\end{proof}
\end{question}


\begin{question}[Докажите, что умножение данной матрицы \(A\) на векторы из пространства \(\mathbb{R}^n\) является линейным преобразованием]\(\)
\begin{proof}
Доказательство остаётся читателю как упражнение. Надо по той же схеме проверить, что оба утверждения выполняются. Я в вас верю. Вы справитесь. 
\end{proof}
\end{question}


\subsection{Билет 9}
\begin{question}[Что такое матрица линейного отображения?]
Пусть \(A\) --- линейное отображение \(V \rightarrow W\), \(e1, \dots, e_n\) --- базис в \(V\), а \(f_1, \dots f_m\) --- базис в \(W\). Тогда матрицей отображения \(A: V \rightarrow W\) называется матрица
\begin{equation*}
	A = 
	\begin{pmatrix}
		a^1_1 & a^1_2 & \dots & a^1_m \\
		a^2_1 & a^2_2 & \dots & a^2_m \\
		\dots & \dots & \dots & \dots \\
		a^n_1 & a^n_2 & \dots & a^n_m
	\end{pmatrix}
\end{equation*}
размера \(n \times m\), в которой \(i\)-й столбец есть вектор \(A(e_i)_f\), т.е. вектор \(A(e_i)\), записанный в базисе \(f = \{f_1, ..., f_m\}\) 
\end{question}

\begin{question}[Как построить эту матрицу, зная образы базисных векторов при данном линейном отображении?]
Ответ дан в предыдущем вопросе.
\end{question}

\begin{question}[Как с её помощью вычисляются координаты образа произвольного вектора?]
Пусть \(x\) --- произвольный вектор из \(V\), а \(A: V \rightarrow W\) --- линейный оператор. Тогда
\begin{equation*}
	A(x) = A \cdot x = Ax
\end{equation*}

\begin{proof}
\begin{equation*}
	Ax =
	\begin{pmatrix}
		a^1_1 & a^1_2 & \dots & a^1_m \\
		a^2_1 & a^2_2 & \dots & a^2_m \\
		\dots & \dots & \dots & \dots \\
		a^n_1 & a^n_2 & \dots & a^n_m
	\end{pmatrix} \cdot 
	\begin{pmatrix}
		x_1 \\
		\vdots \\
		x_m
	\end{pmatrix} =
	\begin{pmatrix}
		\sum_{j = 1}^m a^1_j x_j \\
		\vdots \\
		\sum_{j = 1}^m a^n_j x_j 
	\end{pmatrix}
\end{equation*}
Видим, что \(i\)-й элемент столбца совпадает с \(i\)-й координатой вектора \(A(x)\).
\end{proof}
\end{question}

\begin{question}[Как связаны матрицы линейного оператора на \(n\)-мерном пространстве над произвольным полем \(F\) в старом и новом базисах и матрица перехода?]
Пусть \(A: V \rightarrow V\) --- линейное преобразование, \(A'\) --- матрица этого преобразования в новом базисе, \(S\) --- матрица перехода от старого базиса к новому, тогда
\begin{equation*}
	A' = S^{-1}AS
\end{equation*} 
\begin{proof}
Пусть \(x\) --- произвольный вектор пространства \(V\), \(y\) --- его образ, то есть \(y = A(x) = Ax\). При этом \(x', y'\) --- это эти же векторы в новом базисе. Тогда \(x = Sx', y = Sy'\). Подставим в предыдущую формулу, получим, что \(Sy' = A(Sx')\), откуда получаем \(y' = (S^{-1}AS)x'\). С другой стороны, в новом базисе \(y' = A'x'\). Сравнивая это равенство с предыдущим, получаем, что \(A' = S^{-1}AS\).
\end{proof}
\end{question}


\subsection{Билет 10}
\begin{question}[Что такое ядро линейного отображения?]
Ядро линейного отображения \(\varphi\) --- это полный прообраз нулевого вектора, то есть 
\begin{equation*}
	\ker \varphi = \{\vec{x} \in V\!: \varphi(\vec{x}) = \vec{0}\}
\end{equation*}
\end{question}


\begin{question}[Что такое образ линейного отображения?]
Образ линейного отображения \(\varphi\) --- это множество его значений. Обозначается Im \(\varphi\).
\begin{equation*}
	Im \ \varphi = \{\vec{y} \ |\  \vec{y} = \varphi(\vec{x})\}
\end{equation*}
\end{question}


\begin{question}[Что такое ранг линейного отображения?]
Ранг \(\mathrm{rk}\:A\) линейного отображения \(A\) --- это размерность его образа.
\begin{equation*}
	\mathrm{rk}\:A = \dim \mathrm{Im}\:A
\end{equation*}
\end{question}


\begin{question}[Докажите, что ядро и образ --- линейные пространства]
Пусть \(A: V \rightarrow W\) --- линейное отображение. Тогда ker \(A\) является подпространством в \(V\), а Im \(A\) --- подпространством в \(W\).
\begin{proof}
Пусть \(u, v \in \ker A\), т.е. \(Au = Av = 0\). Тогда \(A(u + v) = Au + Av = 0 + 0 = 0\) и \(A(\lambda{}v) = \lambda{}A(v) = 0\). Следовательно, \(u + v \in \ker A\) и \(\lambda{}v \in \ker A\), а значит \(\ker A\) --- подпространство в V.

Пусть теперь \(x, y \in \mathrm{Im}\:A\), то есть существуют \(u, v \in V\) такие, что \(Au = x\) и \(Av = y\). Тогда \(A(u + v) = x + y\) и \(A(\lambda{}u) = \lambda{}x\). Следовательно, \(x + y \in \mathrm{Im}\:A\) и \(\lambda{}x \in \mathrm{Im}\:A\), а значит \(\mathrm{Im}\:A\) --- подпространство в в \(W\).
\end{proof}
\end{question}

\begin{question}[Как связаны пространства, порождённые строками и столбцами матрицы произвольного отображения \(f: \mathbb{R}^n \rightarrow \mathbb{R}^m\), с его ядром и образом?]
\begin{lemma}[Теорема о сумме ранга и дефекта]
Пусть \(V\) --- векторное пространство, а \(A\) --- линейный оператор в \(V\). Тогда сумма ранга (размерности образа) и дефекта (размерности ядра) оператора \(A\) равна размерности пространства \(V\).

\begin{proof}
Пусть \(x \in V\). Ясно, что \(x \in \ker A\) тогда и только тогда, когда \(Ax = 0\). Иными словами, пространство \(\ker A\) совпадает с пространством решений однородной системы линейных уравнений \(Ax = 0\). Положим, что \(r = \mathrm{rk}(A)\). В силу теоремы о размерности пространства решений однородной системы линейных уравнений, \(\dim \ker A = n - r\). Отсюда получаем, что \(\dim \ker A + \dim \mathrm{A} = n\).
\end{proof}
\end{lemma}


Образ линейного отображения \(f: V \rightarrow W\) порожден столбцами его матрицы \(F\). В самом деле, столбцы \(F\) представляют собой образы векторов \(b_1, b_2, \dots, b_s\), составляющих базис пространства \(V\). Любой вектор из \(V\) есть линейная комбинация \(\{b_i\}\), но тогда в силу линейности оператора \(f\) и любой вектор его образа есть линейная комбинация векторов \(fb_1, fb_2, \dots, fb_s\), то есть столбцов \(F\). Выбрав из них линейно независимые, получаем базис Im \(f\).

Докажем теперь, что ядро матрицы \(F\) --- это дополнение пространства её строк \(R_F\) до \(V\). Проведём доказательство от противного: предположим, что в матрице \(F\) одна из её строк \(F_i \neq \vec{0}\) входит в ядро \(f\). Это означает, что \(F \cdot F_i = \vec{0}\). По определению умножения матриц
\begin{equation*}
	F \cdot F_i =
	\begin{pmatrix}
		F_1 \cdot F_i \\
		\dots \\
		F_i \cdot F_i \\
		\dots \\
		F_m \cdot F_i
	\end{pmatrix} = 
	\begin{pmatrix}
		0 \\
		\dots \\
		0 \\
		\dots \\
		0
	\end{pmatrix},
\end{equation*}
из чего следует, что скалярный квадрат \(F_i\) равен нулю. Но тогда \(F_i = \vec{0}\), что противоречит условию. Получаем, что строка матрицы \(F\) может принадлежать ker \(f\), лишь тогда, когда она равна нулю.

Рассмотрим теперь линейные комбинации строк \(F\), имеющие вид \(v = \alpha_{i_1} F_{i_1} + \alpha_{i_2} F_{i_2} + \dots + \alpha_{i_k} F_{i_k}\), где \(\alpha_{i_j} \neq 0\). Заменим строку \(F_{i_1}\) в матрице \(F\) на эту линейную комбинацию; получим матрицу \(F'\), задающую оператор \(f'\). Из вышесказанного следует, что \(v \notin \ker f'\), но замена одной из её строк на линейную комбинацию с остальными не меняет ядра, поэтому \(v \notin \ker f\).

Таким образом, пересечение ker \(f\) и пространства строк матрицы \(F\) состоит только из нулевого вектора. Но по теореме о ранге и дефекте dim ker \(f\) + rk \(F = \dim V\), поэтому и \(V = \ker f \oplus R_F\). 
\end{question}


\subsection{Билет 11}
\begin{question}[Что такое изоморфизм линейных пространств?]
Биективное (то есть взаимно однозначное) линейное отображение \(A: V \rightarrow W\) называется изоморфизмом. Иначе говоря, два произвольных линейных пространства \(V\) и \(W\) называются изоморфными, если между элементами этих пространств можно установить взаимно однозначное соответствие так, что если элементы \(x, y \in V\) отвечают элементам \(x', y' \in W\) соответственно, то элементу \(x + y \in V\) соответствует элемент \(x' + y' \in W\), а для любого \(\alpha\) над полем \(F\) элементу \(\alpha{}x \in V\) соответствует \(\alpha{}x' \in W\).
\end{question}

\begin{question}[Докажите, что отображение, обратное к изоморфизму, также является изоморфизмом]
Допустим, у нас есть биективное отображение \(A: V \rightarrow W\). Докажем, что \(A^{-1}: W \rightarrow V\) тоже биективно.
\begin{proof}
Из курса дискретной математики мы знаем, что отображение биективно, если оно одновременно инъективно и сюръективно. То есть,
\begin{enumerate}
	\item \(f(x) = f(y) \Rightarrow x = y\)
	\item \(\forall y \in W \exists x \in V: f(x) = y\)
\end{enumerate}

Проверим по очереди каждое из этих свойств для \(A^{-1}\). Предположим, что \(A^{-1}\) не инъективно, то есть \(\exists x \neq y \in W: A^{-1}(x) \neq A^{-1}(y)\). Но тогда нарушается одновременная сюръективность и инъективность прямого отображения \(A\) --- \(\nexists a \neq b \in V: A(a) = x, A(b) = y\). Противоречие.

Предположим, что \(A^{-1}\) не сюръективно, то есть \(\exists a \in V: \nexists x \in W: A^{-1}(x) = a\). Но если \(A^{-1}\) --- обратная функция, и не существует какого-то отображения, значит, и прямого не существует, значит, сюръекция не нарушается 
\end{proof}
\end{question}

\begin{question}[Что происходит при изоморфизме с линейно независимыми векторами?]
Если линейные пространства \(V\) и \(V'\) изоморфны, то система векторов \(a'_1, \dots, a'_k\) линейно зависима тогда и только тогда, когда линейно зависима система векторов \(a_1, \dots, a_k\).
\begin{lemma}[Образ и прообраз нуля при изоморфизме]
При изоморфизме ноль и только ноль является образом нуля
\begin{proof}
Пусть \(a\) --- некоторый вектор в \(V\), \(a'\) --- его образ в \(V'\). Тогда
\begin{equation*}
	a' = (a + 0)' = a' + 0',
\end{equation*}
То есть \(0'\) будет нулём пространства \(V'\)
\end{proof}
\end{lemma}

\begin{proof}
Пусть существуют такие числа \(\alpha_1, \dots, \alpha_k\), не все равные нулю, такие, что
\begin{equation*}
	\alpha_1a_1 + \alpha_2a_2 + \dots + \alpha_ka_k = 0
\end{equation*}
По лемме, образ правой части уравнения --- тоже ноль:
\begin{equation*}
	\alpha_1a_1 + \alpha_2a_2 + \dots + \alpha_ka_k = 0'
\end{equation*}
Используя несколько раз равенства \((a + b)' = a' + b'\) и \((\alpha{}a)' = \alpha{}a'\), получаем, что
\begin{equation*}
	\alpha_1a'_1 + \alpha_2a'_2 + \dots + \alpha_ka'_k = 0' \qedhere
\end{equation*}
\end{proof}
\end{question}

\begin{question}[Докажите, что два конечномерных пространства изоморфны тогда и только тогда, когда они имеют одинаковую размерность]\(\)
\begin{proof}
Из определения изоморфизма и предыдущего вопроса вытекает, что свойства системы векторов быть линейно независимой и порождать всё пространство сохраняются при изоморфизмах, то есть при изоморфизме базис переходит в базис. Следовательно, если \(A: V \rightarrow W\) --- изоморфизм, то \(\dim V = \dim W\). Пусть теперь \(\dim V = \dim W = n\). Выберем базисы \(e_1, \dots, e_n\) и \(f_1, \dots, f_n\) в \(V\) и \(W\) соответственно. Тогда \(Ax_e = x_f\) определяет линейное отображение \(A: V \rightarrow W\). Оно является биекцией, так как \(A^{-1}x_f = x_e\) определяет обратное отображение. Следовательно, \(A\) --- изоморфизм. 
\end{proof}
\end{question}


\subsection{Билет 12}
\begin{question}[Что такое инвариантное подпространство линейного оператора?]
Подпространство \(W \subset V\) называется инвариантным относительно оператора \(A: V \rightarrow V\), если \(A(W) \subset W\).
\end{question}

\begin{question}[Как выглядит матрица линейного оператора в \(n\)-мерном пространстве, если первые \(k\) векторов базиса составляют базис некоторого инвариантного подпространства этого оператора?]
Матрица \(\varphi_b\) линейного оператора \(\varphi: V \rightarrow V\) (где dim \(V = n\)) имеет вид
\begin{equation*}
	\varphi_b =
	\left(\begin{array}{c | c}
		P & Q \\
		\hline
		0 & R
	\end{array}\right),
\end{equation*}
где \(P \in \mathrm{Mat}_{k \times k}, R \in \mathrm{Mat}_{(n-k) \times (n-k)}\) в том и только том случае, когда первые \(k\) базисных векторов порождают инвариантное подпространство \(W \subseteq V\).

\begin{proof}
Матрица линейного оператора состоит из образов базисных векторов, записанных по столбцам. Обозначим эти векторы как \(b_1, \dots, b_k, \dots, b_n\). В образах первых \(k\) векторов ненулевыми могут быть только первые \(k\) координат, поскольку иначе порождённое ими пространство было бы не инвариантным. 
\end{proof}
\end{question}

\begin{question}[Что можно сказать об этой матрице, если и последние \(n - k\) векторов порождают инвариантное подпространство?]
Аналогично рассуждениям в предыдущем вопросе, матрица линейного оператора примет вид 
\begin{equation*}
	\varphi_b =
	\left(\begin{array}{c | c}
		P & 0 \\
		\hline
		0 & R
	\end{array}\right),
\end{equation*}
где \(R\) --- квадратная матрица порядка \(n - k\).
\end{question}


\subsection{Билет 13}
\begin{question}[Что такое собственные вектора и собственные значения линейного оператора?]
Собственный вектор линейного оператора \(\varphi\) --- ненулевой вектор \(x\), образ которого пропорционален самому \(x\), то есть \(\varphi(x) = \lambda \cdot x\). Число \(\lambda\) называется собственным значением.
\end{question}

\begin{question}[Что такое характеристический многочлен и как он связан с собственными значениями?]
Собственные значения линейного оператора \(\varphi\) можно получить, решив характеристическое уравнение 
\begin{equation*}
	\chi_\varphi (\lambda) = \det (\varphi_e - \lambda E) = 0
\end{equation*}

\begin{proof}
Пусть нужно найти все такие числа \(\lambda\), что \(\varphi x = \lambda x\) для некоторых векторов \(x\). Преобразуем равенство:
\begin{align*}
	\varphi x &= \lambda x \\
	\varphi x &= \lambda E x \\
	(\varphi - \lambda E)x &= 0,
\end{align*}
получаем однородную систему линейных уравнений.

Искомые \(\lambda\) --- те, для которых решение СЛАУ неоднозначно. В самом деле, если \(\varphi v = \lambda v\), то и \(\varphi (\mu v) = \lambda (\mu v)\). Иными словами, если \(v\) --- собственный вектор, то и вектор \(\mu v\) также собственный, из чего следует, что размерность собственного пространства не менее \(1\). Но размерность пространства решений СЛАУ ненулевая тогда и только тогда, когда её столбцы линейно зависимы, а в этом случае получаем, что определитель матрицы равен 0. Применяя эти соображения, получаем \(\det (\varphi - \lambda E) = 0\).
\end{proof}
\end{question}

\begin{question}[Найдите собственные векторы и числа оператора дифференцирования в пространстве многочленов степени \(\leqslant n\)]
Для оператора дифференцирования \(D: P_n(\mathbb{R}) \rightarrow P_n(\mathbb{R})\) любой ненулевой многочлен нулевой степени (то есть константа) является собствнным вектором, соответсвующим собственному значению \(\lambda = 0\). Любой многочлен ненулевой степени не является собственным вектором, так как многочлен не пропорционален своей производной, так как они имеют разные степени.
\end{question}

\begin{question}[Найдите собственные векторы и числа оператора проектирования на подпространство в \(\mathbb{R}^n\)]
Рассмотрим оператор \(\Pi_{L_1}: V \rightarrow V\) проектирования на подпространство \(L_1\) параллельно подпространству \(L_2\). Здесь \(V = L_1 \oplus L_2, \Pi_{L_1}(v) = v_1\) для \(v = v_1 + v_2, v_1 \in L_1, v_2 \in L_2\). Для этого оператора любой ненулевой вектор \(v_2 \in L_2\) является собственным, соответствующим собственному значению \(\lambda = 0\), так как \(\Pi_{L_1}(v_2) = 0 \cdot v_2\), а любой ненулевой вектор \(v_1 \in L_1\) является собственным, соответствующим собственному значению \(\lambda = 1\), так как \(\Pi_{L_1}(v_1) = 1 \cdot v_2\). Другие векторы не являются собственными, так как равенство \(\Pi_{L_1}(v_1 + v_2) = v_1 = \lambda{}(v_1 + v_2)\) возможно либо при \(v_1 = 0\), либо при \(v_2 = 0\).
\end{question}

\begin{question}[Найдите собственные векторы и числа оператора поворота]
Для поворота \(R_\varphi: V \rightarrow V\) плоскости (при \(\varphi \neq \pi{}k, k \in \mathbb{Z}\)) собственных векторов нет, так как при повороте на угол, некратный \(\pi\) образ каждого ненулевого вектора неколлинеарен прообразу. 
\end{question}


\subsection{Билет 14}
\begin{question}[Докажите, что у каждого линейного оператора в \(\mathbb{C}^n\) есть собственный вектор]
У каждого линейного оператора над алгебраически замкнутым полем \(n\) собственных чисел.
\begin{proof}
По основной теореме алгебры и теореме Безу, характеристический многочлен разлагается в произведение \(n\) линейных множителей:
\begin{equation*}
	\chi(\lambda) = (-1)^n \prod^n_{i = 1}(\lambda - \lambda_i) \qedhere
\end{equation*}
\end{proof}
\end{question}

\begin{question}[Докажите, что у каждого линейного оператора в \(\mathbb{R}^n\) есть одномерное или двумерное инвариантное подпространство]
По данным от наших лучших людей, этого вопроса на коллоквиуме не будет.
\end{question}


\subsection{Билет 15}
\begin{question}[Докажите, что матрица линейного оператора имеет диагональный вид тогда и только тогда, когда все вектора базиса являются собственными для данного оператора]
Пусть линейное пространство \(V\) порождено базисом \(B = \{b_1, \dots, b_n\}\), где первые \(k\) векторов --- собственные векторы линейного оператора \(\varphi\), каждому из которых соответствует собственное значение \(\lambda_1, \dots, \lambda_k\). Тогда матрица оператора \(\varphi\) имеет вид 
\begin{equation*}
	\Phi = 
	\begin{pmatrix}
		\lambda_1 & 0 & \dots & 0 & a_{1, k+1} & \dots \\
		0 & \lambda_2 & \dots & 0 & a_{2, k+1} & \dots \\
		\dots & \dots & \dots & \dots & \dots & \dots \\
		0 & 0 & \dots & \lambda_k & a_{k, k+1} & \dots \\
		0 & 0 & \dots & 0 & a_{k+1, k+1} & \dots \\
		\dots & \dots & \dots & \dots & \dots & \dots
	\end{pmatrix}
\end{equation*}

Обратно: если матрица линейного оператора в базисе \(b_1, \dots, b_n\) имеет вышеприведённый вид, то \(b_1, \dots, b_k\) --- собственные векторы этого оператора, причём \(\lambda_1, \dots, \lambda_k\) --- собственные значения.

\begin{proof}
Пусть векторы \(b_1, \dots, b_k\) --- собственные. Тогда по определению матрицы линейного оператора, \(i\)-й столбец \(\Phi; (i \leqslant k)\) равен \(\varphi b_i = \lambda_i \cdot b_i\). Его координаты в базисе \(B\) представляют собой вектор вида \((\dots, 0, \lambda_i, 0, \dots)^T\), Где \(\lambda_i\) --- \(i\)-й элемент.

Обратно: если матрица \(\Phi\) имеет вышеприведённый вид, то образ \(i\)-го вектора \(B\) пропорционален этому вектору, причём коэффициент пропорциональности равен \(\lambda_i\). Но это и означает, что \(b_i\) --- собственный вектор, а \(\lambda_i\) --- собственное значение. 

Очевидно, что если матрица имеет диагональный вид, то это просто частный случай, \(i = k\).
\end{proof}
\end{question}

\begin{question}[Докажите, что если все собственные значения линейного оператора различны (то есть все имеют единичную кратность), то этот оператор диагонализуем]\(\)
\begin{proof}
Характеристический многочлен порядка \(n\) имеет \(n\) корней, каждому из которых соответствует собственное пространство размерности \(1\). Если все \(n\) корней различны, то объединение всех собственных пространств имеет размерность \(n\) (так как собственные векторы, соответствующие различным собственным значениям, линейно независимы). Но тогда собственные векторы образуют базис, в котором матрица линейного оператора диагональна.
\end{proof}
\end{question}

\begin{question}[Приведите примеры диагонализуемого и не диагонализуемого оператора]
\begin{equation*}
	\varphi = 
	\begin{pmatrix}
		1 & 1 \\
		0 & 1
	\end{pmatrix};\quad
	\psi = 
	\begin{pmatrix}
		1 & 0 \\
		0 & 1
	\end{pmatrix}
\end{equation*}
Матрица \(\psi\) --- диагонализуема, а \(\varphi\) --- нет. 
\end{question}



\end{document}